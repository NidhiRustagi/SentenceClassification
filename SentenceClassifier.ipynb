{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing all the file names: <br> model_fn: name of the file that stores the trained SVM classifier<br> TRAIN_DATA_FN: file name that contains the training data <br> TEST_FN: file name with test data set. This is currently a .txt file with one english sentence to be tested in a line <br> RESULT_FN: file name that stores the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FN = 'model\\svm_classifier.sav'\n",
    "TRAIN_DATA_FN = 'data\\classification_data.tsv'\n",
    "TEST_FN = 'data\\\\test_samples.txt'\n",
    "RESULT_FN = 'result\\classification_result.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassifier:\n",
    "    # this method acts like a constructor to initialize the basic data structures/files\n",
    "    def __init__(self, trainfn, modelfn, testfn, resultfn):\n",
    "        self.train_fn = trainfn\n",
    "        self.modelfn = modelfn\n",
    "        self.testfn = testfn\n",
    "        self.resultfn = resultfn\n",
    "        text, outcome = self.read()\n",
    "        self.corpus = text.to_list()\n",
    "        self.y = np.array(outcome)\n",
    "        print(\"y.shape : \", self.y.shape)\n",
    "        \n",
    "        self.transformobj, self.featuresX = self.transformFeaturesX()\n",
    "        print(\"Input Features shape (X): \",self.featuresX.shape)\n",
    "        \n",
    "    # to read the training dataset\n",
    "    def read(self):\n",
    "        raw_data = pd.read_csv(self.train_fn, sep=\"\\t\")\n",
    "        return (raw_data['sent'], raw_data['class'])\n",
    "    \n",
    "     #  converts raw english sentences to their vectorized representations\n",
    "    def transformFeaturesX(self):\n",
    "        tfidfobj = TfidfVectorizer(ngram_range = (1,3))\n",
    "        features_X = tfidfobj.fit_transform(self.corpus)\n",
    "#         print(tfidfobj.get_feature_names()[0:10])\n",
    "\n",
    "        return(tfidfobj, features_X)\n",
    "        \n",
    "    # split the training data set into train and validation set.\n",
    "    def generateTrainTestData(self):\n",
    "        self.train_X,self.test_X,self.train_y,self.test_y = train_test_split(self.featuresX, self.y, test_size=0.30, random_state=42)\n",
    "        print(\"Train X : \", self.train_X.shape)\n",
    "        print(\"Test X : \", self.test_X.shape)\n",
    "        print(\"Train y: \", self.train_y.shape)\n",
    "        print(\"Test y :\", self.test_X.shape)\n",
    "        \n",
    "    \n",
    "    # method uses GridSearch to find the optimal values of model hyper-parameters\n",
    "    def optimalModelParam(self):\n",
    "        params ={\n",
    "            'C': [0.1, 1, 10, 100, 1000],\n",
    "            'gamma':[1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel':['linear', 'rbf']\n",
    "        }\n",
    "\n",
    "        grid = GridSearchCV(svm.SVC(), params, refit = True, verbose = 0) \n",
    "        grid.fit(self.train_X, self.train_y)\n",
    "        print(grid.best_params_)\n",
    "        return grid\n",
    "        \n",
    "    # build and train the SVM model\n",
    "    def svmModel(self):\n",
    "        print(\"split train and test set\")\n",
    "        self.generateTrainTestData()\n",
    "        print('checking for optimal param values....')\n",
    "        self.optimalModel = self.optimalModelParam().best_estimator_\n",
    "        self.optimalModel.fit(self.train_X, self.train_y)\n",
    "        #return optimalModel\n",
    "        \n",
    "    def saveModel(self):\n",
    "        pickle.dump(self.optimalModel, open(self.modelfn, \"wb\"))\n",
    "        \n",
    "    def loadModel(self):\n",
    "        self.optimalModel = pickle.load(open(self.modelfn, \"rb\"))\n",
    "        \n",
    "    # Use the trained model above to check with the validation dataset\n",
    "    def validateSVM(self):\n",
    "        predictions = self.optimalModel.predict(self.test_X)\n",
    "        print(metrics.accuracy_score(self.test_y, predictions))\n",
    "        #print(classification_report(self.test_y, predictions))\n",
    "        \n",
    "    # use this method to test inidividual sentence\n",
    "    def testSentence(self, sent):\n",
    "        testcase = self.transformobj.transform(sent)\n",
    "        print(testcase)\n",
    "        \n",
    "        tgt_class = self.optimalModel.predict(testcase)\n",
    "        print(\"target class : \",tgt_class)\n",
    "        if tgt_class:\n",
    "            print(\"Well formed sentence\")\n",
    "        else:\n",
    "            print(\"Needs cleaning.....\")\n",
    "            \n",
    "    # use this method to test sentences stored in a .txt file or .csv file with only one column\n",
    "    def testFileofSentences(self):\n",
    "        raw_test_data = pd.read_csv(self.testfn)\n",
    "        raw_test_data.columns = ['sent']\n",
    "        test_data = raw_test_data['sent'].to_list()\n",
    "        text = self.transformobj.transform(test_data)\n",
    "        \n",
    "        result = self.optimalModel.predict(text)\n",
    "        \n",
    "        result_decoded = [\"good\" if x==1 else \"bad\" for x in result]\n",
    "        result_df = pd.DataFrame(\n",
    "        {\n",
    "            'sentence':raw_test_data['sent'],\n",
    "            'class_code':result,\n",
    "            'class_name':result_decoded\n",
    "        })\n",
    "        \n",
    "        result_df.to_csv(self.resultfn, sep='\\t', index=False)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape :  (10498,)\n",
      "Input Features shape (X):  (10498, 226681)\n",
      "split train and test set\n",
      "Train X :  (7348, 226681)\n",
      "Test X :  (3150, 226681)\n",
      "Train y:  (7348,)\n",
      "Test y : (3150, 226681)\n",
      "checking for optimal param values....\n",
      "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
      "0.9977777777777778\n"
     ]
    }
   ],
   "source": [
    "clsfr = SVMClassifier(TRAIN_DATA_FN, MODEL_FN, TEST_FN, RESULT_FN)\n",
    "clsfr.svmModel()\n",
    "clsfr.validateSVM()\n",
    "clsfr.saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clsfr.loadModel()\n",
    "\n",
    "test_sample_1 = \"this sentence looks perfect\"\n",
    "test_sample_2 = \"perfect no sentence\"\n",
    "clsfr.testSentence([test_sample_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsfr.testSentence([test_sample_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsfr.testSentence(['bulum43h - Stardoll | English'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check for sentences stored in a .txt file, call testFileofSentences() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsfr.testFileofSentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
